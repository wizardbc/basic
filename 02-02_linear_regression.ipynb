{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the Basic (Part 2-2. Linear Regression)\n",
    "\n",
    "* 2023.05.01.(Mon)\n",
    "* Dept. of Math., Inha Univ.\n",
    "* Byung Chun Kim (wizardbc@gmail.com)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "class Module:\n",
    "  def __init__(self):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def set_params(self) -> None:\n",
    "    raise NotImplementedError\n",
    "  \n",
    "  def get_params(self) -> dict:\n",
    "    raise NotImplementedError\n",
    "  \n",
    "  def f(self, x):\n",
    "    raise NotImplementedError\n",
    "  \n",
    "  def __call__(self, x:Iterable) -> tuple:\n",
    "    return tuple([self.f(t) for t in x])\n",
    "\n",
    "\n",
    "class LinearModel(Module):\n",
    "  def __init__(self, weight:float=.0, bias:float=.0) -> None:\n",
    "    self.set_params(weight, bias)\n",
    "\n",
    "  def set_params(self, weight:float, bias:float) -> None:\n",
    "    self.weight = weight\n",
    "    self.bias = bias\n",
    "\n",
    "  def get_params(self) -> dict[str,float]:\n",
    "    return {'weight': self.weight, 'bias':self.bias}\n",
    "\n",
    "  def f(self, x:float) -> float:\n",
    "    params = self.get_params()\n",
    "    w = params.get('weight')\n",
    "    b = params.get('bias')\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5]\n",
    "\n",
    "lin = LinearModel(2.0, 1.0)\n",
    "lin(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error and its Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_\\theta(x) = x w + b$ where $\\theta=(w,b)$.\n",
    "\n",
    "$\\operatorname{MSE}_\\theta(x, y) = \\frac{1}{n}\\sum^n_{i=1}(f(x_i) - y_i)^2 = \\frac{1}{n}\\sum^n_{i=1}(x_iw+b - y_i)^2$.\n",
    "\n",
    "$$\\frac{\\partial}{\\partial w} \\operatorname{MSE}_{\\theta}(x,y) = \\frac{2}{n}\\sum^n_{i=1}x_i(x_iw+b - y_i).$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial b} \\operatorname{MSE}_{\\theta}(x,y) = \\frac{2}{n}\\sum^n_{i=1}(x_iw+b - y_i).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(model:Module, x:Iterable[float], y_true:Iterable[float]) -> float:\n",
    "  assert len(x) == len(y_true)\n",
    "  n = len(x)\n",
    "  y_pred = model(x)\n",
    "  return sum([(t-p)**2 for t,p in zip(y_true, y_pred)])/n\n",
    "\n",
    "def d_mse(model:Module, x:Iterable[float], y_true:Iterable[float]) -> dict[str,float]:\n",
    "  assert len(x) == len(y_true)\n",
    "  n = len(x)\n",
    "  y_pred = model(x)\n",
    "  dw = sum([x*(p-t) for x,p,t in zip(x, y_pred, y_true)])*2/n\n",
    "  db = sum([(p-t) for p,t in zip(y_pred, y_true)])*2/n\n",
    "  return {'d_weight': dw, 'd_bias':db}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(lin, [0.0], [2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mse(lin, [0.0], [2.0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Update $\\theta$: $$\\theta_{\\textrm{new}} = \\theta_{\\textrm{old}} - \\alpha \\nabla\\operatorname{MSE}_{\\theta_{\\textrm{old}}}(x,y)$$ where $\\alpha>0$ is a learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(model:Module, lr:float, d_weight:float, d_bias:float) -> None:\n",
    "  params_old = model.get_params()\n",
    "  params_new = {\n",
    "    'weight': params_old.get('weight') - lr*d_weight,\n",
    "    'bias': params_old.get('bias') - lr*d_bias\n",
    "  }\n",
    "  model.set_params(**params_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset\n",
    "\n",
    "# y = a*x + b\n",
    "f = lambda x: 2.0*x + 1.0\n",
    "\n",
    "xs = tuple([random.uniform(-1,1) for _ in range(1000)])    # 1000 points\n",
    "ys = tuple([f(x)+0.1*random.gauss(0,1) for x in xs])\n",
    "\n",
    "\n",
    "plt.title(\"Dataset\")\n",
    "plt.scatter(xs, ys, s=1)\n",
    "plt.plot(xs, [f(x) for x in xs], label=f\"y =  2x+1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearModel(0.,0.)\n",
    "history = [lin.get_params()]\n",
    "\n",
    "for epoch in range(500):\n",
    "  grad = d_mse(lin, xs, ys)\n",
    "  update(lin, 0.01, **grad)\n",
    "  err = mse(lin, xs, ys)\n",
    "  params = lin.get_params()\n",
    "  history.append(params)\n",
    "  print(f\"Epoch {epoch+1}: mse={err:.4f}, w={params.get('weight'):.4f}, b={params.get('bias'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(history, columns=['weight','bias'])\n",
    "df = df.set_index(df.index.set_names('epoch')).reset_index()\n",
    "df0 = df.copy()\n",
    "df1 = df.copy()\n",
    "df0['x'] = min(xs)\n",
    "df1['x'] = max(xs)\n",
    "df = pd.concat([df0, df1]).reset_index(drop=True)\n",
    "df['y'] = df.weight * df.x + df.bias\n",
    "\n",
    "fig = px.line(df, x='x', y='y', animation_frame=\"epoch\", width=500, height=500)\n",
    "\n",
    "fig.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 0.1\n",
    "fig.layout.updatemenus[0].buttons[0].args[1]['transition']['duration'] = 0.1\n",
    "fig.layout.updatemenus[0].buttons[0].args[1]['frame']['redraw'] = True\n",
    "\n",
    "fig.add_scatter(x=xs, y=ys, mode='markers', name='data', marker={'size':2})\n",
    "\n",
    "for i, frame in enumerate(fig.frames):\n",
    "    frame['layout']['title_text'] = f\"Prediction: y = {history[i]['weight']:.4f}x{'' if history[i]['bias'] < 0 else '+'}{history[i]['bias']:.4f}\"\n",
    "\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
