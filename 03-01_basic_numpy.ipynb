{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the Basic (Part 3-1. NumPy)\n",
    "\n",
    "* 2023.05.22.(Mon)\n",
    "* Dept. of Math., Inha Univ.\n",
    "* Byung Chun Kim (wizardbc@gmail.com)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating arrays\n",
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.zeros((3, 3))\n",
    "arr3 = np.ones((2, 4))\n",
    "arr4 = np.random.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic (element-wise) operations\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "c = a + b\n",
    "d = a - b\n",
    "e = a * b\n",
    "f = a / b\n",
    "\n",
    "display(c)\n",
    "display(d)\n",
    "display(e)\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix operations\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6], [7, 8]])\n",
    "c = np.dot(a, b)      # or a@b\n",
    "d = np.transpose(a)   # or a.T\n",
    "\n",
    "display(a)\n",
    "display(b)\n",
    "display(c)\n",
    "display(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more operations\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "display(arr)\n",
    "display(arr.sum(axis=0))\n",
    "display(arr.sum(axis=1))\n",
    "display(arr.mean(axis=0))\n",
    "display(arr.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "det = np.linalg.det(arr)\n",
    "inv = np.linalg.inv(arr)\n",
    "eigvals, eigvecs = np.linalg.eig(arr)\n",
    "\n",
    "display(arr)\n",
    "display(det)\n",
    "display(inv)\n",
    "display(eigvals, eigvecs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "* Broadcasting is just a scalar operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting with a scalar\n",
    "arr = np.array([1, 2, 3])\n",
    "a = 2\n",
    "b = arr + a\n",
    "\n",
    "display(b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbb{R^{2\\times 2}}$ can be considered as a 2-dimensional vector space over $\\mathbb{R}^2$ which equals to $(\\mathbb{R}^{2})^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting with arrays of different shapes\n",
    "arr1 = np.array([[1, 2], [3, 4]])\n",
    "arr2 = np.array([1, 2])\n",
    "c = arr1 + arr2\n",
    "\n",
    "display(arr1)\n",
    "display(arr2[:, np.newaxis])\n",
    "display(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing and slicing a 1D array\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "display(arr[0])\n",
    "display(arr[-1])\n",
    "display(arr[1:4])\n",
    "display(arr[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing and slicing a 2D array\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "display(arr[0, 1])\n",
    "display(arr[:, 1])\n",
    "display(arr[0:2, 1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshapeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping a 1D array in NumPy\n",
    "arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "new_arr = arr.reshape(2, 3)\n",
    "display(arr)\n",
    "display(new_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping a 2D array in NumPy\n",
    "arr = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "new_arr = arr.reshape(2, 3)\n",
    "\n",
    "display(arr.shape)\n",
    "display(arr)\n",
    "\n",
    "display(new_arr.shape)\n",
    "display(new_arr)\n",
    "\n",
    "display(arr.flatten().shape)\n",
    "display(arr.flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `np.einsum` (Einstein summation convention)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer Product (Tensor Product)\n",
    "* [Wikipedia/Outer_product](https://en.wikipedia.org/wiki/Outer_product#The_outer_product_of_tensors)\n",
    "  \n",
    "  Given two tensors $\\mathbb{u}, \\mathbb{v}$ with dimensions $(k_1,k_2,\\ldots,k_m)$ and $(l_1,l_2,\\ldots,l_n)$,\n",
    "  their outer product $(\\mathbb{u}\\otimes\\mathbb{v})$ is tensor with dimensions $(k_1,k_2,\\ldots,k_m,l_1,l_2,\\ldots,l_n)$ and entries\n",
    "  $$(\\mathbb{u}\\otimes\\mathbb{v})_{k_1,k_2,\\ldots,k_m,l_1,l_2,\\ldots,l_n}=u_{k_1,k_2,\\ldots,k_m}v_{l_1,l_2,\\ldots,l_n}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(0, 10, size=(3,2))\n",
    "B = np.random.randint(0, 10, size=(2,2))\n",
    "\n",
    "C = np.einsum('ij, kl -> ijkl', A, B)\n",
    "C.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'ij, kl -> ijkl'`\n",
    "* `'ij'` and `'kl'` are indices for input tensors `A` and `B`, respectively.\n",
    "* `'ijkl'` after the arrow shows the indices of the output tensor.\n",
    "* If all indices are on the right, like `'ijkl'`, no summation is performed.\n",
    "\n",
    "This subscripts corresponding to the notation:\n",
    "$c_{ijkl} = a_{ij}b_{kl}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(0,10, size=(3,4))\n",
    "display(A)\n",
    "\n",
    "B = np.einsum('ij -> i', A)\n",
    "display(B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'ij -> i'`\n",
    "* If an index is omitted on the rhs, sum over that index.\n",
    "\n",
    "This subscripts corresponding to the notation: $b_i = \\sum_j a_{ij}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication\n",
    "\n",
    "$A=(a_{ij}), B=(b_{jk})$, and $C=(c_{ik})$ where\n",
    "$$c_{ik} = \\sum_j a_{ij}b_{jk}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(0,10, size=(2,3))\n",
    "B = np.random.randint(0,10, size=(3,4))\n",
    "\n",
    "# perform matrix multiplication using np.einsum\n",
    "C = np.einsum('ij, jk -> ik', A, B)\n",
    "display(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(A@B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the string `'ij, jk -> ik'` specifies the following:\n",
    "\n",
    "* `'ij'`: Take the elements from the first matrix `A` along the rows and columns\n",
    "* `', '`: Comma separates the input arrays\n",
    "* `'jk'`: Take the elements from the second matrix `B` along the rows and columns\n",
    "* `'->'`: Arrow specifies the output shape\n",
    "* `'ik'`: Take the resulting elements and reshape them into the shape of the output matrix `C`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,10, size=(3,))\n",
    "b = np.random.randint(0,10, size=(3,))\n",
    "\n",
    "# compute dot product using np.einsum\n",
    "c = np.einsum('i, i ->', a, b)\n",
    "display(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(a@b.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a = (a_i), b = (b_i),$\n",
    "$$c = \\sum_i a_ib_i.$$\n",
    "\n",
    "In this example, the string `'i, i ->'` specifies the following:\n",
    "\n",
    "* `'i'`: Take the elements from the first vector `a` along the index\n",
    "* `', '`: Comma separates the input arrays\n",
    "* `'i'`: Take the elements from the second vector `b` along the index\n",
    "* `'->'`: Arrow specifies the output shape\n",
    "* `''`: Compute the dot product of the two vectors and return a scalar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(0,10,size=(2,2))\n",
    "B = np.random.randint(0,10,size=(2,2))\n",
    "display(A,B)\n",
    "# perform element-wise multiplication using np.einsum\n",
    "C = np.einsum('ij, ij -> ij', A, B)\n",
    "display(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(A*B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A = (a_{ij}), B = (b_{ij})$, and $C = (c_{ij})$ where\n",
    "$$c_{ij} = a_{ij}b_{ij}.$$\n",
    "\n",
    "In this example, the string `'ij, ij -> ij'` specifies the following:\n",
    "\n",
    "* `'ij'`: Take the elements from the first matrix `A` along the rows and columns\n",
    "* `', '`: Comma separates the input arrays\n",
    "* `'ij'`: Take the elements from the second matrix `B` along the rows and columns\n",
    "* `'->'`: Arrow specifies the output shape\n",
    "* `'ij'`: Place the resulting elements in the same shape as the input matrices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batched dot product\n",
    "\n",
    "$A = (a_{ij}), b = (b_{bj})$, and $C = (c_{bi})$ where\n",
    "$$c_{bi} = \\sum_j a_{ij}b_{bj}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(0,10,size=(2,3))\n",
    "b = np.random.rand(100, 3)\n",
    "\n",
    "display(A.shape)\n",
    "display(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.einsum('ij, bj -> bi', A, b)\n",
    "display(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = (A[np.newaxis,:,:] * b[:,np.newaxis,:]).sum(axis=2)\n",
    "display(D.shape)\n",
    "display(np.isclose(C,D).all())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the string `'ij, bj -> bi'` specifies the following:\n",
    "\n",
    "* `'ij'`: Take elements from the first input `A` along the rows and columns\n",
    "* `', '`: Comma separates the input arrays\n",
    "* `'bj'`: Take elements from the second input `b` along the batch and columns\n",
    "* `'->'`: Arrow specifies the output shape\n",
    "* `'bi'`: Place the resulting elements in the same shape as the output array `C`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset\n",
    "\n",
    "# y = a*x + b\n",
    "f = lambda x: x*2.0 + 1.0\n",
    "\n",
    "xs = np.random.rand(1000, 1)   # 1000 points\n",
    "ys = f(xs) + 0.1*np.random.randn(1000, 1)\n",
    "\n",
    "plt.title(\"Dataset\")\n",
    "plt.scatter(xs, ys, s=1)\n",
    "plt.plot(xs, f(xs), label=f\"y = 2x + 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A model is a mathematical function $f_{\\theta}:X\\rightarrow Y$ with some parameters $\\theta$.\n",
    "* We need:\n",
    "  * a function $f$,\n",
    "  * a way to set and get parameters,\n",
    "  * ~~a way to process a bunch (called a batch) of inputs.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "class Module:\n",
    "  def __init__(self) -> None:\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def set_params(self) -> None:\n",
    "    raise NotImplementedError\n",
    "  \n",
    "  def get_params(self) -> dict:\n",
    "    raise NotImplementedError\n",
    "  \n",
    "  def f(self, x:np.array) -> np.array:\n",
    "    raise NotImplementedError\n",
    "  \n",
    "  def __call__(self, x:np.array) -> np.array:\n",
    "    return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(Module):\n",
    "  def __init__(self, w:float=.0, b:float=.0) -> None:\n",
    "    self.set_params(w, b)\n",
    "\n",
    "  def set_params(self, w:float, b:float) -> None:\n",
    "    self.w = w\n",
    "    self.b = b\n",
    "\n",
    "  def get_params(self) -> dict[str,float]:\n",
    "    return {'w': self.w, 'b':self.b}\n",
    "\n",
    "  def f(self, x:np.array) -> np.array:\n",
    "    params = self.get_params()\n",
    "    w = params.get('w')\n",
    "    b = params.get('b')\n",
    "    return w * x + b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_\\theta(x) = x w + b$ where $\\theta=(w,b)$.\n",
    "\n",
    "$\\operatorname{MSE}_\\theta(x, y) = \\frac{1}{n}\\sum^n_{i=1}(f(x_i) - y_i)^2 = \\frac{1}{n}\\sum^n_{i=1}(x_iw+b - y_i)^2$.\n",
    "\n",
    "$$\\frac{\\partial}{\\partial w} \\operatorname{MSE}_{\\theta}(x,y) = \\frac{2}{n}\\sum^n_{i=1}x_i(x_iw+b - y_i).$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial b} \\operatorname{MSE}_{\\theta}(x,y) = \\frac{2}{n}\\sum^n_{i=1}(x_iw+b - y_i).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(model:Module, x:np.array, y_true:np.array) -> float:\n",
    "  assert len(x) == len(y_true)\n",
    "  y_pred = model(x)\n",
    "  return ((y_pred - y_true)**2).mean()\n",
    "\n",
    "def grad_mse(model:Module, x:np.array, y_true:np.array) -> dict[str,float]:\n",
    "  assert len(x) == len(y_true)\n",
    "  n = len(x)\n",
    "  y_pred = model(x)\n",
    "  d_w = 2*(x*(y_pred-y_true)).mean()\n",
    "  d_b = 2*(y_pred-y_true).mean()\n",
    "  return {'d_w': d_w, 'd_b':d_b}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Update $\\theta$: $$\\theta_{\\textrm{new}} = \\theta_{\\textrm{old}} - \\alpha \\nabla\\operatorname{MSE}_{\\theta_{\\textrm{old}}}(x,y)$$ where $\\alpha>0$ is a learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(model:Module, lr:float, d_w:float, d_b:float) -> None:\n",
    "  params_old = model.get_params()\n",
    "  params_new = {\n",
    "    'w': params_old.get('w') - lr*d_w,\n",
    "    'b': params_old.get('b') - lr*d_b,\n",
    "  }\n",
    "  model.set_params(**params_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearModel(0.,0.)\n",
    "history = [lin.get_params()]\n",
    "\n",
    "for epoch in range(200):\n",
    "  grad = grad_mse(lin, xs, ys)\n",
    "  update(lin, 0.2, **grad)\n",
    "  err = mse(lin, xs, ys)\n",
    "  params = lin.get_params()\n",
    "  history.append(params)\n",
    "  print(f\"Epoch {epoch+1}: mse={err:.4f}, w={params.get('w'):.4f}, b={params.get('b'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(history, columns=['w','b'])\n",
    "df = df.set_index(df.index.set_names('epoch')).reset_index()\n",
    "df0 = df.copy()\n",
    "df1 = df.copy()\n",
    "df0['x'] = xs.min()\n",
    "df1['x'] = xs.max()\n",
    "df = pd.concat([df0, df1]).reset_index(drop=True)\n",
    "df['y'] = df.w * df.x + df.b\n",
    "\n",
    "fig = px.line(df, x='x', y='y', animation_frame=\"epoch\", width=500, height=500)\n",
    "\n",
    "fig.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 0.1\n",
    "fig.layout.updatemenus[0].buttons[0].args[1]['transition']['duration'] = 0.1\n",
    "fig.layout.updatemenus[0].buttons[0].args[1]['frame']['redraw'] = True\n",
    "\n",
    "fig.add_scatter(x=xs.flatten(), y=ys.flatten(), mode='markers', name='data', marker={'size':2})\n",
    "\n",
    "for i, frame in enumerate(fig.frames):\n",
    "    frame['layout']['title_text'] = f\"Prediction: y = {history[i]['w']:.4f}x{'' if history[i]['b'] < 0 else '+'}{history[i]['b']:.4f}\"\n",
    "\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
